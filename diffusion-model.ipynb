{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***Imports***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:27:51.557058Z","iopub.status.busy":"2023-06-04T23:27:51.556299Z","iopub.status.idle":"2023-06-04T23:27:51.752418Z","shell.execute_reply":"2023-06-04T23:27:51.751265Z","shell.execute_reply.started":"2023-06-04T23:27:51.557002Z"},"trusted":true},"outputs":[],"source":["import glob\n","import re\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook,tqdm\n","from PIL import Image\n","import os\n","from os import listdir\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:27:51.755143Z","iopub.status.busy":"2023-06-04T23:27:51.754655Z","iopub.status.idle":"2023-06-04T23:28:01.247649Z","shell.execute_reply":"2023-06-04T23:28:01.246486Z","shell.execute_reply.started":"2023-06-04T23:27:51.755100Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers,Model,Sequential\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import Progbar,pad_sequences\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***Utils***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:01.250449Z","iopub.status.busy":"2023-06-04T23:28:01.249326Z","iopub.status.idle":"2023-06-04T23:28:01.258898Z","shell.execute_reply":"2023-06-04T23:28:01.257874Z","shell.execute_reply.started":"2023-06-04T23:28:01.250404Z"},"trusted":true},"outputs":[],"source":["SHAPE = (64,64)\n","nb_image = 400\n","BATCH_SIZE = 64\n","SEED = 42\n","# set to true if you want to generate images depending on a class\n","embedding_state = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:01.262372Z","iopub.status.busy":"2023-06-04T23:28:01.261914Z","iopub.status.idle":"2023-06-04T23:28:01.272362Z","shell.execute_reply":"2023-06-04T23:28:01.271163Z","shell.execute_reply.started":"2023-06-04T23:28:01.262333Z"},"trusted":true},"outputs":[],"source":["def embedding_text(y,tokenizer,dim):\n","    y = tokenizer.texts_to_sequences(y)\n","    y = pad_sequences(y,maxlen=dim,padding='post')\n","    return y \n","\n","# Save a GIF using logged images\n","def save_gif(img_list, path=\"\", interval=200):\n","    # Transform images from [-1,1] to [0, 255]\n","    imgs = []\n","    for im in img_list:\n","        im = (im + 1) * 127.5\n","        im = np.clip(im, 0, 255).astype(np.uint8)\n","        im = Image.fromarray(im)\n","        imgs.append(im)\n","    \n","    imgs = iter(imgs)\n","    # Extract first image from iterator\n","    img = next(imgs)\n","    # Append the other images and save as GIF\n","    img.save(fp=path, format='GIF', append_images=imgs,\n","             save_all=True, duration=interval, loop=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***Dataset***"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Emojies datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:01.274545Z","iopub.status.busy":"2023-06-04T23:28:01.273929Z","iopub.status.idle":"2023-06-04T23:28:02.079265Z","shell.execute_reply":"2023-06-04T23:28:02.078019Z","shell.execute_reply.started":"2023-06-04T23:28:01.274505Z"},"trusted":true},"outputs":[],"source":["values_location = \"values.npy\"\n","targets_location = \"targets.npy\"\n","\n","\n","emoji_captions = pd.read_csv(\"/kaggle/input/emojiimage-dataset/full_emoji.csv\")\n","\n","image_file_apple = \"/kaggle/input/emojiimage-dataset/image/Apple/\"\n","image_file_facebook = \"/kaggle/input/emojiimage-dataset/image/Facebook\"\n","image_file_google = \"/kaggle/input/emojiimage-dataset/image/Google/\"\n","image_file_joypixels = \"/kaggle/input/emojiimage-dataset/image/JoyPixels/\"\n","image_file_samsung = \"/kaggle/input/emojiimage-dataset/image/Samsung/\"\n","image_file_twitter = \"/kaggle/input/emojiimage-dataset/image/Twitter/\"\n","image_file_windows = \"/kaggle/input/emojiimage-dataset/image/Windows/\"\n","\n","\n","    # images_apple = np.array(os.listdir(image_file_apple))\n","    # images_facebook = np.array(os.listdir(image_file_facebook))\n","    # images_google = np.array(os.listdir(image_file_google))\n","    # images_joypixels = np.array(os.listdir(image_file_joypixels))\n","    # images_samsung = np.array(os.listdir(image_file_samsung))\n","    # images_twitter = np.array(os.listdir(image_file_twitter))\n","    # images_windows = np.array(os.listdir(image_file_windows))\n","\n","images_apple = []\n","images_facebook =[]\n","images_google = []\n","images_joypixels = []\n","images_samsung = []\n","images_twitter = []\n","images_windows = []\n","\n","\n","for i in range(1, nb_image):\n","    images_apple.append(os.path.join(image_file_apple, str(i) + '.png')) # Replace .jpg with the extension of your images\n","    images_facebook.append(os.path.join(image_file_facebook, str(i) + '.png')) # Replace .jpg with the extension of your images\n","    images_google.append(os.path.join(image_file_google, str(i) + '.png')) # Replace .jpg with the extension of your images\n","    images_joypixels.append(os.path.join(image_file_joypixels, str(i) + '.png')) # Replace .jpg with the extension of your images\n","    images_samsung.append(os.path.join(image_file_samsung, str(i) + '.png')) # Replace .jpg with the extension of your images\n","    images_twitter.append(os.path.join(image_file_twitter, str(i) + '.png')) # Replace .jpg with the extension of your images\n","    images_windows.append(os.path.join(image_file_windows, str(i) + '.png')) # Replace .jpg with the extension of your images\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Human faces"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:02.087978Z","iopub.status.busy":"2023-06-04T23:28:02.084740Z","iopub.status.idle":"2023-06-04T23:28:02.102126Z","shell.execute_reply":"2023-06-04T23:28:02.100903Z","shell.execute_reply.started":"2023-06-04T23:28:02.087927Z"},"trusted":true},"outputs":[],"source":["def create_dataset_from(image_1,image_2,image_3,image_4,image_5,image_6,image_7):\n","    values = []\n","    target = []\n","    for i,images in enumerate(zip(image_1,image_2,image_3,image_4,image_5,image_6,image_7) ):\n","        for im in images : \n","            index = int(re.findall('\\d+', im)[-1])\n","            captions = emoji_captions[emoji_captions[\"#\"]==index]['name'].values[0]\n","            image = cv2.imread(im)\n","            if type(image) != type(None):\n","                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","                resized_image = cv2.resize(image,SHAPE)\n","                values.append(resized_image)\n","                target.append(captions)\n","    \n","    np.save(values_location,values,allow_pickle=True)\n","    np.save(targets_location,target,allow_pickle=True)\n","\n","    return np.array(values),np.array(target)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:02.111402Z","iopub.status.busy":"2023-06-04T23:28:02.108274Z","iopub.status.idle":"2023-06-04T23:28:13.588174Z","shell.execute_reply":"2023-06-04T23:28:13.587001Z","shell.execute_reply.started":"2023-06-04T23:28:02.111359Z"},"trusted":true},"outputs":[],"source":["values,targets = create_dataset_from(\n","    images_apple,\n","    images_facebook,\n","    images_google,\n","    images_joypixels,\n","    images_samsung,\n","    images_twitter,\n","    images_windows\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Showing shapes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:13.590406Z","iopub.status.busy":"2023-06-04T23:28:13.589659Z","iopub.status.idle":"2023-06-04T23:28:13.613805Z","shell.execute_reply":"2023-06-04T23:28:13.612683Z","shell.execute_reply.started":"2023-06-04T23:28:13.590359Z"},"trusted":true},"outputs":[],"source":["values = np.load(values_location,allow_pickle=True)\n","targets = np.load(targets_location,allow_pickle=True)\n","\n","print(values.shape)\n","print(targets.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Showing dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:13.616568Z","iopub.status.busy":"2023-06-04T23:28:13.615616Z","iopub.status.idle":"2023-06-04T23:28:14.622771Z","shell.execute_reply":"2023-06-04T23:28:14.621717Z","shell.execute_reply.started":"2023-06-04T23:28:13.616526Z"},"trusted":true},"outputs":[],"source":["def show_dataset(values,targets):\n","    born_inf = np.random.randint(0,values.shape[0]-9)\n","    born_sup = born_inf+9\n","    \n","    plt.figure(figsize=(20,12))\n","    for p,i in enumerate(range(born_inf,born_sup)):\n","        plt.subplot(3,3,p+1)\n","        plt.imshow(values[i])\n","        plt.title(targets[i])\n","    plt.show()\n","    \n","    \n","    \n","show_dataset(values,targets)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:14.627913Z","iopub.status.busy":"2023-06-04T23:28:14.627585Z","iopub.status.idle":"2023-06-04T23:28:14.704893Z","shell.execute_reply":"2023-06-04T23:28:14.703818Z","shell.execute_reply.started":"2023-06-04T23:28:14.627880Z"},"trusted":true},"outputs":[],"source":["classes = {\n","    \"person\":\"person\",\n","    \"man\":\"person\",\n","    \"woman\":\"person\",\n","    \"face\":\"face\",\n","    \"cat\":\"animal\",\n","    \"dog\":\"animal\",\n","    \"monkey\":\"animal\",\n","    \"hand\":\"hand\",\n","    \"finger\":\"hand\",\n","    \"thumb\":\"hand\",\n","    \"fist\":\"hand\",\n","    \"palms\":\"hand\",\n","    \"heart\":\"heart\",\n","    \"other\":\"other\"\n","}\n","\n","def change_to_class(y):\n","    for i,caption in enumerate(y) : \n","        found = False\n","        for key in classes.keys():\n","            if key in caption:\n","                found = True\n","                y[i] = classes[key]\n","                break\n","        if not found : \n","            y[i] = \"other\"\n","            \n","    return y \n","\n","def preprocess_text(y,length=64,classe=True):\n","    if classe : \n","        y = change_to_class(y)\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(y)\n","    y = tokenizer.texts_to_sequences(y)\n","    y = pad_sequences(y,maxlen=length,padding='post')\n","    return y,tokenizer\n","\n","\n","targets,tokenizer_obj = preprocess_text(targets,classe=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:14.708118Z","iopub.status.busy":"2023-06-04T23:28:14.706568Z","iopub.status.idle":"2023-06-04T23:28:14.722970Z","shell.execute_reply":"2023-06-04T23:28:14.721804Z","shell.execute_reply.started":"2023-06-04T23:28:14.708067Z"},"trusted":true},"outputs":[],"source":["X_train,X_test,y_train,y_test = train_test_split(values,targets,test_size=0.1,random_state=SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:14.725153Z","iopub.status.busy":"2023-06-04T23:28:14.724728Z","iopub.status.idle":"2023-06-04T23:28:17.583094Z","shell.execute_reply":"2023-06-04T23:28:17.581897Z","shell.execute_reply.started":"2023-06-04T23:28:14.725112Z"},"trusted":true},"outputs":[],"source":["def make_batch(y):\n","    y = tf.convert_to_tensor(y, dtype=tf.float32)\n","    y = convert_to_dataset(y)\n","    y = y.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","    return y\n","\n","def preprocess(x) -> np.ndarray :        \n","    x = tf.convert_to_tensor(x)\n","    x = tf.math.divide(x, 255)\n","    x = x * 2 - 1 \n","    x = convert_to_dataset(x)\n","    x = x.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","    return x\n","\n","def convert_to_dataset(x)-> tf.Tensor:\n","    return tf.data.Dataset.from_tensor_slices(x)\n","\n","\n","X_train = preprocess(X_train)\n","X_test = preprocess(X_test)\n","\n","y_train = make_batch(y_train)\n","y_test = make_batch(y_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***Forward Process***"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Adding gaussian noise gradually"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:17.585273Z","iopub.status.busy":"2023-06-04T23:28:17.584852Z","iopub.status.idle":"2023-06-04T23:28:17.598283Z","shell.execute_reply":"2023-06-04T23:28:17.596628Z","shell.execute_reply.started":"2023-06-04T23:28:17.585226Z"},"trusted":true},"outputs":[],"source":["timesteps = 300\n","\n","# create a fixed beta schedule\n","# beta is the variance\n","beta = np.linspace(0.0001, 0.02, timesteps)\n","\n","# this will be used as discussed in the reparameterization trick\n","# instead of calculating iteratively xt/xt-1 we can find xt/x0\n","\n","alpha = 1 - beta\n","alpha_bar = np.cumprod(alpha, 0)\n","alpha_bar = np.concatenate((np.array([1.]), alpha_bar[:-1]), axis=0)\n","sqrt_alpha_bar = np.sqrt(alpha_bar)\n","one_minus_sqrt_alpha_bar = np.sqrt(1-alpha_bar)\n","\n","# this function will help us set the RNG key for Numpy\n","def set_key(key):\n","    np.random.seed(key)\n","\n","# this function will add noise to the input as per the given timestamp\n","def forward_noise(key, x_0, t):\n","    set_key(key)\n","    noise = np.random.normal(size=x_0.shape)\n","    reshaped_sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), (-1, 1, 1, 1))\n","    reshaped_one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), (-1, 1, 1, 1))\n","    noisy_image = reshaped_sqrt_alpha_bar_t  * x_0 + reshaped_one_minus_sqrt_alpha_bar_t  * noise\n","    return noisy_image, noise\n","\n","# this function will be used to create sample timestamps between 0 & T\n","def generate_timestamp(key, num):\n","    set_key(key)\n","    return tf.random.uniform(shape=[num], minval=0, maxval=timesteps, dtype=tf.int32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:17.601645Z","iopub.status.busy":"2023-06-04T23:28:17.600503Z","iopub.status.idle":"2023-06-04T23:28:18.938953Z","shell.execute_reply":"2023-06-04T23:28:18.937815Z","shell.execute_reply.started":"2023-06-04T23:28:17.601588Z"},"trusted":true},"outputs":[],"source":["def show_foward_dataset():\n","    timesteps_range =  np.arange(10,timesteps,30)\n","\n","    X_train_noise = next(iter(X_train))\n","\n","    fig = plt.figure(figsize=(15, 30))\n","\n","    for index, i in enumerate(timesteps_range):\n","        # expanded_x_train_noise = np.expand_dims(X_train_noise, 0)\n","        noisy_im, noise = forward_noise(0, X_train_noise, np.array([i,]))\n","        squeezed_image = np.squeeze(noisy_im)\n","        plt.subplot(1, len(timesteps_range), index+1)\n","        plt.imshow(squeezed_image[0,:,:,:],cmap='gray')\n","\n","    plt.show()\n","\n","show_foward_dataset()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***CNN Model U-NET***"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Unet-block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:18.941825Z","iopub.status.busy":"2023-06-04T23:28:18.941445Z","iopub.status.idle":"2023-06-04T23:28:18.957986Z","shell.execute_reply":"2023-06-04T23:28:18.956895Z","shell.execute_reply.started":"2023-06-04T23:28:18.941786Z"},"trusted":true},"outputs":[],"source":["class BlockUnet(layers.Layer):\n","    def __init__(self,in_channels,out_channels,time_embedding,side='encoder'):\n","        super(BlockUnet,self).__init__()\n","        # specify the current timestep\n","        self.timestep_mlp = layers.Dense(units=out_channels, input_shape=(time_embedding,))\n","\n","        if side == 'encoder':\n","            # downsampling\n","            self.conv_1 = layers.Conv2D(\n","                filters=out_channels,\n","                kernel_size=(3,3),\n","                padding='same',\n","                # input_shape=(None, None, 2*in_channels)\n","            )\n","            \n","            self.transform = layers.Conv2D(\n","                filters=out_channels,\n","                kernel_size=(4,4),\n","                strides=(2,2),\n","                padding='same'\n","            )\n","        else:\n","            # upsampling\n","            self.conv_1 = layers.Conv2D(\n","                filters=out_channels,\n","                kernel_size=(3,3),\n","                padding='same',\n","                input_shape=(None, None, 2*in_channels)\n","            )\n","            self.transform = layers.Conv2DTranspose(\n","                filters=out_channels,\n","                kernel_size=(4,4),\n","                strides=(2,2),\n","                padding='same'\n","            )\n","            \n","        self.conv_2 = layers.Conv2D(filters=out_channels,kernel_size=(3,3),padding='same')\n","        self.bn_1 = layers.BatchNormalization()\n","        self.bn_2 = layers.BatchNormalization()\n","        self.relu = layers.ReLU()\n","\n","    def call(self,X,t):\n","        h = self.conv_1(X)\n","        h = self.relu(h)\n","        h = self.bn_1(h)\n","\n","        time_embedding = self.timestep_mlp(t)\n","        time_embedding = self.relu(time_embedding)\n","        time_embedding = time_embedding[..., None, None, :]\n","\n","        h += time_embedding\n","\n","        h = self.conv_2(h)\n","        h = self.relu(h)\n","        h = self.bn_2(h)\n","        h = self.transform(h)\n","        return h\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Unet-sinus-block for calculating time-embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:18.960142Z","iopub.status.busy":"2023-06-04T23:28:18.959622Z","iopub.status.idle":"2023-06-04T23:28:18.973927Z","shell.execute_reply":"2023-06-04T23:28:18.972886Z","shell.execute_reply.started":"2023-06-04T23:28:18.960066Z"},"trusted":true},"outputs":[],"source":["class SinusoidalPositionEmbeddings(layers.Layer):\n","    def __init__(self, dim, max_positions=10000):\n","        super(SinusoidalPositionEmbeddings, self).__init__()\n","        self.dim = dim\n","        self.max_positions = np.array(max_positions,dtype=np.float32)\n","\n","    def call(self, x, training=True):\n","        x = tf.cast(x, tf.float32)\n","        half_dim = self.dim // 2\n","        emb = tf.math.log(self.max_positions) / (half_dim - 1)\n","        emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n","        emb = x[:, None] * emb[None, :]\n","\n","        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n","\n","        return emb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:18.975779Z","iopub.status.busy":"2023-06-04T23:28:18.975346Z","iopub.status.idle":"2023-06-04T23:28:18.989268Z","shell.execute_reply":"2023-06-04T23:28:18.988227Z","shell.execute_reply.started":"2023-06-04T23:28:18.975738Z"},"trusted":true},"outputs":[],"source":["def gelu(x):\n","    # approximation of gaussien error\n","    coeff = tf.cast(0.044715, x.dtype)\n","    return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n","   \n","class GELU(layers.Layer):\n","    def __init__(self):\n","        super(GELU, self).__init__()\n","\n","    def call(self, x, training=True):\n","        return gelu(x)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Unet-class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:18.991388Z","iopub.status.busy":"2023-06-04T23:28:18.991052Z","iopub.status.idle":"2023-06-04T23:28:19.010199Z","shell.execute_reply":"2023-06-04T23:28:19.009055Z","shell.execute_reply.started":"2023-06-04T23:28:18.991350Z"},"trusted":true},"outputs":[],"source":["class Unet(Model):\n","    \n","    def __init__(self,image_dim):\n","        super(Unet,self).__init__()\n","        # time embedding \n","        self.dim = SHAPE[0]\n","        self.image_dim = image_dim\n","\n","        self.time_embedding_mlp = Sequential([\n","            SinusoidalPositionEmbeddings(self.dim),\n","            layers.Dense(self.dim),\n","            GELU(),\n","            layers.Dense(self.dim),\n","# #             layers.ReLU()\n","        ])\n","\n","        self.first_conv = layers.Conv2D(filters=64,kernel_size=(3,3),padding='same')\n","        self.encoders = [\n","            BlockUnet(64,128,self.dim,side='encoder'),\n","            BlockUnet(128,256,self.dim,side='encoder'),\n","            BlockUnet(256,512,self.dim,side='encoder'),\n","            BlockUnet(512,1024,self.dim,side='encoder'),\n","        ]\n","        self.decoders = [\n","            BlockUnet(1024,512,self.dim,side='decoder'),\n","            BlockUnet(512,256,self.dim,side='decoder'),\n","            BlockUnet(256,128,self.dim,side='decoder'),\n","            BlockUnet(128,64,self.dim,side='decoder'),\n","        ]\n","        self.last_conv = layers.Conv2D(filters=self.image_dim,kernel_size=(1,1))\n","        \n","    def call(self,X,y,current_timestep,embedding=True,training=True):\n","        t = self.time_embedding_mlp(current_timestep)\n","        if embedding : \n","            t+=y\n","        X = self.first_conv(X)\n","        \n","        residual_connexion = []\n","\n","        for encoder in self.encoders:\n","            X = encoder(X, t)\n","            residual_connexion.append(X)\n","\n","        for decoder in self.decoders:\n","            residual_x = residual_connexion.pop()\n","            # Add residual x as additional channels\n","            X = tf.concat([X, residual_x], axis=-1)\n","            X = decoder(X, t)\n","        X = self.last_conv(X)\n","        return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:19.012363Z","iopub.status.busy":"2023-06-04T23:28:19.011985Z","iopub.status.idle":"2023-06-04T23:28:19.130770Z","shell.execute_reply":"2023-06-04T23:28:19.129705Z","shell.execute_reply.started":"2023-06-04T23:28:19.012324Z"},"trusted":true},"outputs":[],"source":["model = Unet(image_dim=3)\n","opt = Adam(learning_rate=1e-4)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:19.133909Z","iopub.status.busy":"2023-06-04T23:28:19.133131Z","iopub.status.idle":"2023-06-04T23:28:19.139991Z","shell.execute_reply":"2023-06-04T23:28:19.138912Z","shell.execute_reply.started":"2023-06-04T23:28:19.133863Z"},"trusted":true},"outputs":[],"source":["@tf.function\n","def loss_of(noise,noise_pred):\n","    noise = tf.cast(noise,dtype=noise_pred.dtype)\n","    return tf.math.reduce_mean(tf.square(noise-noise_pred))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***Training***"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Training-step function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:32.954880Z","iopub.status.busy":"2023-06-04T23:28:32.954448Z","iopub.status.idle":"2023-06-04T23:28:32.962480Z","shell.execute_reply":"2023-06-04T23:28:32.961112Z","shell.execute_reply.started":"2023-06-04T23:28:32.954823Z"},"trusted":true},"outputs":[],"source":["@tf.function\n","def train_step(timestep_values,noised_image,noise,captions):\n","    # calculate loss and update parameters\n","    with tf.GradientTape() as tape:\n","        prediction = model(noised_image,captions, timestep_values,embedding=embedding_state)\n","        loss_value = loss_of(noise, prediction)\n","    gradients = tape.gradient(loss_value, model.trainable_variables)\n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\n","    return loss_value"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:34.140995Z","iopub.status.busy":"2023-06-04T23:28:34.139927Z","iopub.status.idle":"2023-06-04T23:28:34.147579Z","shell.execute_reply":"2023-06-04T23:28:34.146353Z","shell.execute_reply.started":"2023-06-04T23:28:34.140954Z"},"trusted":true},"outputs":[],"source":["@tf.function\n","def validation_step(timestep_values,noised_image,noise,captions):\n","    # calculate loss and update parameters\n","    prediction = model(noised_image,captions, timestep_values,embedding=embedding_state,training=False)\n","    loss_value = loss_of(noise, prediction)\n","    return loss_value"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-04T23:28:40.138303Z","iopub.status.busy":"2023-06-04T23:28:40.137907Z","iopub.status.idle":"2023-06-05T00:01:59.066728Z","shell.execute_reply":"2023-06-05T00:01:59.065552Z","shell.execute_reply.started":"2023-06-04T23:28:40.138266Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 180\n","training_loss = []\n","val_loss = []\n","\n","for e in tf.range(EPOCHS):\n","    print(f\"epoch  : {e+1}/{EPOCHS}\")\n","    pb_i = Progbar(len(X_train), stateful_metrics=('loss','val_loss'))\n","    \n","    batch_loss = []\n","    for i,batchs in enumerate(zip(X_train,y_train)):\n","        batch_x,batch_y = batchs\n","        rng, tsrng = np.random.randint(0, 100000, size=(2,))\n","        # generate a timestep\n","        timestep_values = generate_timestamp(tsrng, batch_x.shape[0])\n","        # generate a noise_image\n","        noised_image, noise = forward_noise(rng, batch_x, timestep_values)\n","        # convert parameters to tensor because of @tf.function\n","        noised_image = tf.convert_to_tensor(noised_image)\n","        noise = tf.convert_to_tensor(noise)\n","        timestep_values = tf.constant(timestep_values)        \n","        # calculate loss and update parameters\n","        loss = train_step(timestep_values,noised_image,noise,batch_y)\n","        batch_loss.append(loss)\n","        # showing progress\n","        values=[('loss',loss)]\n","        pb_i.add(1, values=values)\n","        \n","    val_batch_loss = []\n","    for batchs in zip(X_test,y_test):\n","        batch_x,batch_y = batchs\n","        \n","        rng, tsrng = np.random.randint(0, 100000, size=(2,))\n","        # generate a timestep\n","        timestep_values = generate_timestamp(tsrng, batch_x.shape[0])\n","        # generate a noise_image\n","        noised_image, noise = forward_noise(rng, batch_x, timestep_values)\n","        # convert parameters to tensor because of @tf.function\n","        noised_image = tf.convert_to_tensor(noised_image)\n","        noise = tf.convert_to_tensor(noise)\n","        timestep_values = tf.constant(timestep_values)        \n","        # calculate loss and update parameters\n","        loss = validation_step(timestep_values,noised_image,noise,batch_y)\n","        val_batch_loss.append(loss)\n","            \n","    val_loss.append(sum(val_batch_loss)/len(val_batch_loss))\n","    training_loss.append(sum(batch_loss)/len(batch_loss))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Saving model and creating zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T00:02:09.394922Z","iopub.status.busy":"2023-06-05T00:02:09.394305Z","iopub.status.idle":"2023-06-05T00:02:19.200187Z","shell.execute_reply":"2023-06-05T00:02:19.199094Z","shell.execute_reply.started":"2023-06-05T00:02:09.394877Z"},"trusted":true},"outputs":[],"source":["model_path = 'diffusion-model'\n","model.save(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T00:02:19.205916Z","iopub.status.busy":"2023-06-05T00:02:19.205041Z","iopub.status.idle":"2023-06-05T00:02:33.482738Z","shell.execute_reply":"2023-06-05T00:02:33.481419Z","shell.execute_reply.started":"2023-06-05T00:02:19.205871Z"},"trusted":true},"outputs":[],"source":["!zip -r file.zip 'diffusion-model'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T00:02:33.485714Z","iopub.status.busy":"2023-06-05T00:02:33.485257Z","iopub.status.idle":"2023-06-05T00:02:33.874921Z","shell.execute_reply":"2023-06-05T00:02:33.873859Z","shell.execute_reply.started":"2023-06-05T00:02:33.485666Z"},"trusted":true},"outputs":[],"source":["for i in range(len(val_loss)):\n","    if val_loss[i]>1:\n","        val_loss[i]=1\n","\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(val_loss, label=\"val_loss\")\n","plt.plot(training_loss, label=\"train_loss\")\n","plt.title(\"Results\")\n","plt.xlabel(\"Epochs #\")\n","plt.ylabel(\"Loss\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig(\"plot.png\")\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***DDPM (Denoising Diffusion Probabilistic Model)***"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Algorithm to denoise"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T00:02:33.877121Z","iopub.status.busy":"2023-06-05T00:02:33.876707Z","iopub.status.idle":"2023-06-05T00:02:33.884550Z","shell.execute_reply":"2023-06-05T00:02:33.883443Z","shell.execute_reply.started":"2023-06-05T00:02:33.877071Z"},"trusted":true},"outputs":[],"source":["# algorithm in the paper\n","def ddpm(x_t, pred_noise, t):\n","    alpha_t = np.take(alpha, t)\n","    alpha_t_bar = np.take(alpha_bar, t)\n","\n","    eps_coef = (1 - alpha_t) / (1 - alpha_t_bar) ** .5\n","    mean = (1 / (alpha_t ** .5)) * (x_t - eps_coef * pred_noise)\n","\n","    var = np.take(beta, t)\n","    z = np.random.normal(size=x_t.shape)\n","\n","    return mean + (var ** .5) * z"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T00:02:33.887211Z","iopub.status.busy":"2023-06-05T00:02:33.886372Z","iopub.status.idle":"2023-06-05T00:02:38.439245Z","shell.execute_reply":"2023-06-05T00:02:38.438071Z","shell.execute_reply.started":"2023-06-05T00:02:33.887168Z"},"trusted":true},"outputs":[],"source":["model_path = 'diffusion-model'\n","model = load_model(model_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ***Generation test***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T00:08:20.002709Z","iopub.status.busy":"2023-06-05T00:08:20.002299Z","iopub.status.idle":"2023-06-05T00:09:44.859828Z","shell.execute_reply":"2023-06-05T00:09:44.858876Z","shell.execute_reply.started":"2023-06-05T00:08:20.002673Z"},"trusted":true},"outputs":[],"source":["nb_dim = 3\n","\n","def show_result(prompt,nb_image):\n","    dim = 64\n","    captions = embedding_text(prompt,tokenizer_obj,dim)\n","    captions = tf.convert_to_tensor(captions[0].reshape(-1,dim),dtype=tf.float32)        \n","    plt.figure(figsize=(12,7))\n","    for k in tqdm_notebook(range(nb_image)):\n","        # create random noise\n","        rng = np.random.randint(0, 100000, size=(1,))\n","        set_key(rng)\n","\n","        # Generate a tensor with random values using the normal distribution\n","        x = tf.random.normal(shape=(1, SHAPE[0], SHAPE[1], nb_dim))\n","\n","        img_list = []\n","        img_list.append(np.squeeze(x))\n","\n","        for i in range(timesteps-1):\n","            t = np.expand_dims(np.array(timesteps-i-1, np.int32), 0)\n","            # predict noise for an image\n","            pred_noise = model(x,captions, t)            \n","            if k==0 and i == 0:\n","                print(model.summary())\n","            # get the denoised image\n","            x = ddpm(x, pred_noise, t)\n","            # add it\n","            img_list.append(np.squeeze(x))\n","\n","        plt.subplot(int(np.sqrt(nb_image)),int(np.sqrt(nb_image)),(k+1))\n","        plt.title(f\"Generated emoji {k+1}\")\n","        plt.imshow(np.array(np.clip((x[0] + 1) * 127.5, 0, 255), np.uint8))\n","        \n","        # range [0-1]\n","        save_gif(img_list + ([img_list[-1]] * 100), f\"ddpm_0{k+1}.gif\", interval=20)\n","    plt.show()\n","\n","    \n","# enter a class : face/heart/hand/other/animal/person\n","show_result(prompt=\"hand\",nb_image=9)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
